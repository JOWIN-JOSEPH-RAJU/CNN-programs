{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "846530bb-f088-44cd-9237-fbae468ea49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1939 images belonging to 3 classes.\n",
      "Found 552 images belonging to 3 classes.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 21:08:44.843209: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 42s 577ms/step - loss: 0.9432 - accuracy: 0.5926 - val_loss: 0.7613 - val_accuracy: 0.6431\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 34s 559ms/step - loss: 0.8056 - accuracy: 0.6338 - val_loss: 0.7623 - val_accuracy: 0.6431\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 35s 565ms/step - loss: 0.8029 - accuracy: 0.6349 - val_loss: 0.7664 - val_accuracy: 0.6431\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 35s 573ms/step - loss: 0.8007 - accuracy: 0.6349 - val_loss: 0.7631 - val_accuracy: 0.6431\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 34s 561ms/step - loss: 0.8023 - accuracy: 0.6349 - val_loss: 0.7614 - val_accuracy: 0.6431\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 34s 555ms/step - loss: 0.8010 - accuracy: 0.6349 - val_loss: 0.7674 - val_accuracy: 0.6431\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 34s 555ms/step - loss: 0.8053 - accuracy: 0.6338 - val_loss: 0.7670 - val_accuracy: 0.6431\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 34s 553ms/step - loss: 0.7965 - accuracy: 0.6349 - val_loss: 0.7802 - val_accuracy: 0.6431\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 35s 582ms/step - loss: 0.8012 - accuracy: 0.6349 - val_loss: 0.7667 - val_accuracy: 0.6431\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 33s 548ms/step - loss: 0.7996 - accuracy: 0.6349 - val_loss: 0.7650 - val_accuracy: 0.6431\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 35s 581ms/step - loss: 0.8009 - accuracy: 0.6349 - val_loss: 0.7684 - val_accuracy: 0.6431\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 34s 557ms/step - loss: 0.7998 - accuracy: 0.6349 - val_loss: 0.7719 - val_accuracy: 0.6431\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 37s 600ms/step - loss: 0.7986 - accuracy: 0.6349 - val_loss: 0.7608 - val_accuracy: 0.6431\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 34s 562ms/step - loss: 0.7985 - accuracy: 0.6349 - val_loss: 0.7637 - val_accuracy: 0.6431\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 34s 564ms/step - loss: 0.8026 - accuracy: 0.6349 - val_loss: 0.7663 - val_accuracy: 0.6431\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 36s 590ms/step - loss: 0.8002 - accuracy: 0.6349 - val_loss: 0.7740 - val_accuracy: 0.6431\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 35s 570ms/step - loss: 0.8074 - accuracy: 0.6318 - val_loss: 0.7647 - val_accuracy: 0.6431\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 38s 619ms/step - loss: 0.7990 - accuracy: 0.6323 - val_loss: 0.7744 - val_accuracy: 0.6431\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 36s 590ms/step - loss: 0.8022 - accuracy: 0.6349 - val_loss: 0.7631 - val_accuracy: 0.6431\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 35s 570ms/step - loss: 0.8007 - accuracy: 0.6349 - val_loss: 0.7627 - val_accuracy: 0.6431\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 34s 562ms/step - loss: 0.7987 - accuracy: 0.6349 - val_loss: 0.7620 - val_accuracy: 0.6431\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 36s 588ms/step - loss: 0.8011 - accuracy: 0.6297 - val_loss: 0.7786 - val_accuracy: 0.6431\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 36s 591ms/step - loss: 0.8007 - accuracy: 0.6349 - val_loss: 0.7778 - val_accuracy: 0.6431\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 35s 572ms/step - loss: 0.8060 - accuracy: 0.6338 - val_loss: 0.7670 - val_accuracy: 0.6431\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 34s 561ms/step - loss: 0.8004 - accuracy: 0.6349 - val_loss: 0.7662 - val_accuracy: 0.6431\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 35s 577ms/step - loss: 0.8056 - accuracy: 0.6313 - val_loss: 0.7668 - val_accuracy: 0.6431\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 34s 553ms/step - loss: 0.8000 - accuracy: 0.6349 - val_loss: 0.7608 - val_accuracy: 0.6431\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 34s 561ms/step - loss: 0.8044 - accuracy: 0.6323 - val_loss: 0.7950 - val_accuracy: 0.6431\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 34s 565ms/step - loss: 0.8022 - accuracy: 0.6313 - val_loss: 0.7608 - val_accuracy: 0.6431\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 33s 544ms/step - loss: 0.8058 - accuracy: 0.6349 - val_loss: 0.7617 - val_accuracy: 0.6431\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 35s 572ms/step - loss: 0.8038 - accuracy: 0.6349 - val_loss: 0.7618 - val_accuracy: 0.6431\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 34s 557ms/step - loss: 0.8016 - accuracy: 0.6349 - val_loss: 0.7664 - val_accuracy: 0.6431\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 34s 565ms/step - loss: 0.8035 - accuracy: 0.6349 - val_loss: 0.7651 - val_accuracy: 0.6431\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 41s 677ms/step - loss: 0.8007 - accuracy: 0.6349 - val_loss: 0.7724 - val_accuracy: 0.6431\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 38s 612ms/step - loss: 0.8005 - accuracy: 0.6349 - val_loss: 0.7626 - val_accuracy: 0.6431\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 34s 561ms/step - loss: 0.7987 - accuracy: 0.6349 - val_loss: 0.7679 - val_accuracy: 0.6431\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 37s 601ms/step - loss: 0.8013 - accuracy: 0.6343 - val_loss: 0.7660 - val_accuracy: 0.6431\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 33s 547ms/step - loss: 0.8021 - accuracy: 0.6349 - val_loss: 0.7638 - val_accuracy: 0.6431\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 35s 570ms/step - loss: 0.7988 - accuracy: 0.6349 - val_loss: 0.7658 - val_accuracy: 0.6431\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 35s 571ms/step - loss: 0.8019 - accuracy: 0.6349 - val_loss: 0.7832 - val_accuracy: 0.6431\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 37s 603ms/step - loss: 0.8025 - accuracy: 0.6349 - val_loss: 0.7648 - val_accuracy: 0.6431\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 36s 595ms/step - loss: 0.8069 - accuracy: 0.6333 - val_loss: 0.7708 - val_accuracy: 0.6431\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 37s 614ms/step - loss: 0.8025 - accuracy: 0.6318 - val_loss: 0.7732 - val_accuracy: 0.6431\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 34s 565ms/step - loss: 0.8042 - accuracy: 0.6349 - val_loss: 0.7749 - val_accuracy: 0.6431\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 34s 557ms/step - loss: 0.7981 - accuracy: 0.6349 - val_loss: 0.7626 - val_accuracy: 0.6431\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 34s 555ms/step - loss: 0.8041 - accuracy: 0.6349 - val_loss: 0.7651 - val_accuracy: 0.6431\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 35s 575ms/step - loss: 0.8028 - accuracy: 0.6349 - val_loss: 0.7614 - val_accuracy: 0.6431\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 34s 557ms/step - loss: 0.8005 - accuracy: 0.6349 - val_loss: 0.7630 - val_accuracy: 0.6431\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 37s 607ms/step - loss: 0.7992 - accuracy: 0.6261 - val_loss: 0.7713 - val_accuracy: 0.6431\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 36s 591ms/step - loss: 0.8027 - accuracy: 0.6349 - val_loss: 0.7626 - val_accuracy: 0.6431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x321dd30d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define Image DataGenerators for data augmentation (optional)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Define training and validation data paths (replace with your paths)\n",
    "train_dir = \"/Users/jowinjosephraju/Miniproject/D:/mini project/Testing videos/Ex-Guard 2/train\"\n",
    "val_dir = \"/Users/jowinjosephraju/Miniproject/D:/mini project/Testing videos/Ex-Guard 2/valid\"\n",
    "\n",
    "# Set image dimensions (same as AlexNet input)\n",
    "img_width, img_height = 224, 224\n",
    "num_classes=3\n",
    "# Define AlexNet architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=64, kernel_size=(11, 11), strides=(4, 4), activation=\"relu\", input_shape=(img_width, img_height, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Conv2D(filters=192, kernel_size=(5, 5), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Conv2D(filters=384, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))  # Replace num_classes with your actual number of classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs_50alexnet/\",histogram_freq=1)\n",
    "\n",
    "\n",
    "# Load training and validation data using the generators (optional for augmentation)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,  # Adjust batch size based on your hardware\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=50, validation_data=val_generator,callbacks=[tb_callback])  # Adjust epochs for training time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33aec6dd-a66a-480d-b515-ed2a8a29e383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jowinjosephraju/Miniproject/tensorenv/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model (optional)\n",
    "model.save(\"alexnet_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c92dfa9e-e3cd-40b8-b883-d35bb125a488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-613bce74c6e58054\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-613bce74c6e58054\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs_50alexnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3111bb47-ec96-4983-98d6-7aef18aa6a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jowinjosephraju/Miniproject/tensorenv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/jowinjosephraju/Miniproject/tensorenv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /Users/jowinjosephraju/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
      "  6%|██████▎                                                                                                            | 12.9M/233M [00:08<02:24, 1.60MB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Load pre-trained AlexNet model\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malexnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Freeze feature extraction layers (transfer learning)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mparameters():\n",
      "File \u001b[0;32m~/Miniproject/tensorenv/lib/python3.11/site-packages/torchvision/models/_utils.py:142\u001b[0m, in \u001b[0;36mkwonly_to_pos_or_kw.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_to_str(\u001b[38;5;28mtuple\u001b[39m(keyword_only_kwargs\u001b[38;5;241m.\u001b[39mkeys()),\u001b[38;5;250m \u001b[39mseparate_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as positional \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    140\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(keyword_only_kwargs)\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Miniproject/tensorenv/lib/python3.11/site-packages/torchvision/models/_utils.py:228\u001b[0m, in \u001b[0;36mhandle_legacy_interface.<locals>.outer_wrapper.<locals>.inner_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[pretrained_param]\n\u001b[1;32m    226\u001b[0m     kwargs[weights_param] \u001b[38;5;241m=\u001b[39m default_weights_arg\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Miniproject/tensorenv/lib/python3.11/site-packages/torchvision/models/alexnet.py:117\u001b[0m, in \u001b[0;36malexnet\u001b[0;34m(weights, progress, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m model \u001b[38;5;241m=\u001b[39m AlexNet(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Miniproject/tensorenv/lib/python3.11/site-packages/torchvision/models/_api.py:90\u001b[0m, in \u001b[0;36mWeightsEnum.get_state_dict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Mapping[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_state_dict_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Miniproject/tensorenv/lib/python3.11/site-packages/torch/hub.py:766\u001b[0m, in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name, weights_only)\u001b[0m\n\u001b[1;32m    764\u001b[0m         r \u001b[38;5;241m=\u001b[39m HASH_REGEX\u001b[38;5;241m.\u001b[39msearch(filename)  \u001b[38;5;66;03m# r is Optional[Match[str]]\u001b[39;00m\n\u001b[1;32m    765\u001b[0m         hash_prefix \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 766\u001b[0m     \u001b[43mdownload_url_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location, weights_only)\n",
      "File \u001b[0;32m~/Miniproject/tensorenv/lib/python3.11/site-packages/torch/hub.py:651\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mfile_size, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m progress,\n\u001b[1;32m    649\u001b[0m           unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, unit_divisor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 651\u001b[0m         buffer \u001b[38;5;241m=\u001b[39m \u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8192\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    653\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    472\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 473\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1315\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1314\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from tensorboardX import SummaryWriter  # Assuming you have TensorBoard installed\n",
    "\n",
    "# Define hyperparameters\n",
    "num_classes = 3  # Replace with the number of classes in your dataset\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "\n",
    "# Define data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),  # Resize (adjust as needed)\n",
    "        transforms.RandomResizedCrop(224),  # Randomly crop and resize to 224x224 (AlexNet input size)\n",
    "        transforms.RandomHorizontalFlip(),  # Random horizontal flip (optional)\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize for ImageNet\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),  # Resize (adjust as needed)\n",
    "        transforms.CenterCrop(224),  # Center crop and resize to 224x224\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Define custom datasets (replace with your implementation)\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Load image paths and labels from your dataset directory structure (modify as needed)\n",
    "        for class_name in os.listdir(data_dir):\n",
    "            class_path = os.path.join(data_dir, class_name)\n",
    "            for filename in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, filename)\n",
    "                self.image_paths.append(image_path)\n",
    "                self.labels.append(your_class_list.index(class_name))  # Assuming class names in directory names\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = cv2.imread(image_path)  # Use OpenCV to read the image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB format (if needed)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# Load pre-trained AlexNet model\n",
    "model = torchvision.models.alexnet(pretrained=True)\n",
    "\n",
    "# Freeze feature extraction layers (transfer learning)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the final classifier for your num_classes\n",
    "num_ftrs = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define custom datasets for training and validation (replace with your data paths)\n",
    "train_data_dir = \n",
    "val_data_dir = \n",
    "\n",
    "train_dataset = MyDataset(train_data_dir, transform=data_transforms['train'])\n",
    "val_dataset = MyDataset(val_data_dir, transform=data_transforms['val'])\n",
    "\n",
    "# Create data loaders\n",
    "train_data = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_data = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Create a TensorBoard writer instance (specify a log directory)\n",
    "writer = SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c4b81f-019c-4ad8-9a19-cce67a3e47d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
